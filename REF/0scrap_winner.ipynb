{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **| Scrapping 1,000 Additional Data for predicting which categories have the most oppotunity to get the research prize**\n",
    "\n",
    "##### 1. extract_data_lasker(url, target_data_count=20, output_csv='extracted_data.csv') \n",
    "This part will scrap data from https://laskerfoundation.org/all-awards-winners/ and get all winner detail in each link ~ 337 link\n",
    "##### 2. extract_data(url, target_data_count=20, output_csv='extracted_data_2.csv') \n",
    "This part will scrap data from https://www.nobelprize.org/prizes/lists/all-nobel-prizes/ and get all winner detail in each link ~ 800 link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening page: https://laskerfoundation.org/all-awards-winners/\n",
      "16\n",
      "32\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "def extract_data_lasker(url, target_data_count=20, output_csv='extracted_data.csv'):\n",
    "    print(f\"Opening page: {url}\")  # Print progress as soon as the page starts loading\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration (useful for some environments)\n",
    "    webdriver_path = r\"C:\\users\\asus\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "    # Create a Service object\n",
    "    service = Service(webdriver_path)\n",
    "    \n",
    "    # Initialize the WebDriver using the Service object\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        data = []\n",
    "        collected_count = 0  # Counter for the number of collected items\n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        articles = soup.find_all('article')\n",
    "        while(len(articles) < 500):\n",
    "            soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(3)\n",
    "            articles = soup.find_all('article')\n",
    "            print(len(articles))\n",
    "            if(len(articles) == 336):break\n",
    "        for article in articles:\n",
    "            title_author = article.find('div', {'class': 'fusion-post-content post-content'})\n",
    "            a_title = title_author.find('a')\n",
    "            author_name = title_author.find('p')\n",
    "            title_link = a_title['href'] if a_title else None \n",
    "\n",
    "\n",
    "            year_prize_a = article.find('div', {'class' : \"fusion-meta-info\"})\n",
    "            year_prize = year_prize_a.find_all('a')\n",
    "            year = year_prize[1]\n",
    "            prize = year_prize[2]\n",
    "\n",
    "\n",
    "\n",
    "            if a_title and author_name:\n",
    "                data.append([a_title.text.strip(), author_name.text.strip(), year.text.strip(), prize.text.strip(), title_link])  # Append both title and author to the list\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")  # Log errors during scraping\n",
    "        data = []\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    print(f\"Finished scraping: {url}\")  # Notify when scraping for this URL is complete\n",
    "    print(f\"Collected {collected_count} items.\")\n",
    "    \n",
    "#     # Save data to CSV\n",
    "    save_to_csv(data, output_csv)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Saves the collected data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Title', 'Author', 'Year', 'Type of Prize', 'url'])  # Write the header row with both Title and Author\n",
    "            writer.writerows(data)  # Write the collected data\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "\n",
    "# Example usage\n",
    "extracted_data = extract_data_lasker(\"https://laskerfoundation.org/all-awards-winners/\")\n",
    "print(f\"Total data collected: {len(extracted_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to scopus_results.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 59\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Save the full HTML content to a file\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m full_html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscopus_full_html.html\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m html_file:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:485\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m:Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m        driver.page_source\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_PAGE_SOURCE)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:384\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    385\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.109)\nStacktrace:\n\tGetHandleVerifier [0x00007FF659016CB5+28821]\n\t(No symbol) [0x00007FF658F83840]\n\t(No symbol) [0x00007FF658E2578A]\n\t(No symbol) [0x00007FF658DFF4F5]\n\t(No symbol) [0x00007FF658EA6247]\n\t(No symbol) [0x00007FF658EBECE2]\n\t(No symbol) [0x00007FF658E9F0A3]\n\t(No symbol) [0x00007FF658E6A778]\n\t(No symbol) [0x00007FF658E6B8E1]\n\tGetHandleVerifier [0x00007FF65934FCAD+3408013]\n\tGetHandleVerifier [0x00007FF65936741F+3504127]\n\tGetHandleVerifier [0x00007FF65935B5FD+3455453]\n\tGetHandleVerifier [0x00007FF6590DBDBB+835995]\n\t(No symbol) [0x00007FF658F8EB5F]\n\t(No symbol) [0x00007FF658F8A814]\n\t(No symbol) [0x00007FF658F8A9AD]\n\t(No symbol) [0x00007FF658F7A199]\n\tBaseThreadInitThunk [0x00007FFD66AC259D+29]\n\tRtlUserThreadStart [0x00007FFD6760AF38+40]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\socket.py:848\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    847\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 848\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull HTML content saved to scopus_full_html.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Close the WebDriver\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:193\u001b[0m, in \u001b[0;36mChromiumDriver.quit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:152\u001b[0m, in \u001b[0;36mService.stop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_remote_shutdown_command()\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:137\u001b[0m, in \u001b[0;36mService.send_remote_shutdown_command\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connectable():\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     sleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:126\u001b[0m, in \u001b[0;36mService.is_connectable\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_connectable\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Establishes a socket connection to determine if the service running\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    on the port is accessible.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_connectable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\selenium\\webdriver\\common\\utils.py:101\u001b[0m, in \u001b[0;36mis_connectable\u001b[1;34m(port, host)\u001b[0m\n\u001b[0;32m     99\u001b[0m socket_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     socket_ \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mcreate_connection((host, port), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _is_connectable_exceptions:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\dsde-cedt\\Lib\\socket.py:855\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 855\u001b[0m         exceptions\u001b[38;5;241m.\u001b[39mclear()  \u001b[38;5;66;03m# raise only the last error\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     exceptions\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import json\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "webdriver_path = r\"C:\\users\\asus\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    " # Create a Service object\n",
    "service = Service(webdriver_path)\n",
    "\n",
    "# Initialize the WebDriver using the Service object\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# URL of the Scopus record\n",
    "url = \"https://www.scopus.com/record/display.uri?eid=2-s2.0-85179929360&origin=inward\"\n",
    "\n",
    "try:\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the content to load (adjust time as necessary)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # Extract the title\n",
    "    title = driver.title.strip()\n",
    "\n",
    "    # Extract the abstract section\n",
    "    try:\n",
    "        abstract_section = driver.find_element(By.ID, \"abstractSection\")\n",
    "        abstract = abstract_section.find_element(By.TAG_NAME, \"p\").text.strip()\n",
    "    except Exception:\n",
    "        abstract = \"Abstract not found\"\n",
    "\n",
    "    # Extract the author keywords (adjust the selector if necessary)\n",
    "    try:\n",
    "        keyword_elements = driver.find_elements(By.CSS_SELECTOR, \"#authorKeywords .badges\")\n",
    "        keywords = [keyword.text for keyword in keyword_elements]\n",
    "    except Exception:\n",
    "        keywords = []\n",
    "\n",
    "    # Prepare data for saving\n",
    "    data = {\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"author_keywords\": keywords\n",
    "    }\n",
    "    \n",
    "    # Save data to a JSON file\n",
    "    with open(\"scopus_results.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "    print(\"Data saved to scopus_results.json\")\n",
    "\n",
    "    # Save the full HTML content to a file\n",
    "    full_html = driver.page_source\n",
    "    with open(\"scopus_full_html.html\", \"w\", encoding=\"utf-8\") as html_file:\n",
    "        html_file.write(full_html)\n",
    "    print(\"Full HTML content saved to scopus_full_html.html\")\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening page: https://www.nobelprize.org/prizes/lists/all-nobel-prizes/\n",
      "Clicked cookie banner accept button.\n",
      "Clicked 'Load More' button successfully.\n",
      "Found 90 new articles.\n",
      "Found 90 articles so far.\n",
      "Finished scraping: https://www.nobelprize.org/prizes/lists/all-nobel-prizes/\n",
      "Data saved to extracted_data_2.csv\n",
      "Total data collected: 90\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def extract_data(url, output_csv='extracted_data_2.csv'):\n",
    "    print(f\"Opening page: {url}\")  # Print progress as soon as the page starts loading\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration (useful for some environments)\n",
    "    webdriver_path = r\"C:\\users\\asus\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "    # Create a Service object\n",
    "    service = Service(webdriver_path)\n",
    "    \n",
    "    # Initialize the WebDriver using the Service object\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")  # Python HTML parser\n",
    "        data = []\n",
    "\n",
    "        articles = soup.find_all('div', {'class': 'card-prize'})\n",
    "        cookie_found = False\n",
    "\n",
    "        while(len(articles) < 40): \n",
    "            \n",
    "            if(not cookie_found):\n",
    "                time.sleep(2)\n",
    "                cookie_banner = WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))\n",
    "                )\n",
    "                if(cookie_banner) : \n",
    "                    cookie_banner.click()  # Click the \"Accept\" button or close the banner\n",
    "                    print(\"Clicked cookie banner accept button.\")\n",
    "                    cookie_found = True\n",
    "\n",
    "            # Wait for and click the \"Load More\" button\n",
    "            try:\n",
    "                load_more_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, \"dynamic-list-load-more\"))\n",
    "                )\n",
    "                load_more_button.click()  # Click the 'Load More' button\n",
    "                print(\"Clicked 'Load More' button successfully.\")\n",
    "            except Exception as e:\n",
    "                print(\"Load More button not found or error:\", e)\n",
    "                break  # If no \"Load More\" button is found, exit the loop\n",
    "\n",
    "            # Wait for the page to load more content\n",
    "            time.sleep(3)  # Wait for 3 seconds for the page to load more data\n",
    "\n",
    "            # Re-parse the page again after clicking 'Load More'\n",
    "            soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "\n",
    "            # Extract articles\n",
    "            articles = soup.find_all('div', {'class': 'card-prize'})\n",
    "            print(f\"Found {len(articles)} new articles.\")\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            articles = soup.find_all('div', {'class': 'card-prize'})\n",
    "            print(f\"Found {len(articles)} articles so far.\")\n",
    "            for article in articles:\n",
    "                try:\n",
    "                    author_section = article.find('div', {'class': 'card-prize--laureates--links'})\n",
    "                    authors = [author.text.strip() for author in author_section.find_all('a')] if author_section else []\n",
    "\n",
    "                    title = article.find('blockquote', {'class': 'card-prize--laureates--motivation --last'})\n",
    "                    title_text = title.text.strip() if title else \"\"\n",
    "                    clean_title = title_text.replace(\"“\", \"\").replace(\"”\", \"\").replace('\"', '').lstrip(\"for \").strip()\n",
    "\n",
    "                    element = article.find('h3')\n",
    "                    element_a = element.find('a') if element else None\n",
    "                    link = element_a['href'] if element_a else None\n",
    "                    full_text = element_a.text if element_a else \"\"\n",
    "\n",
    "                    parts = full_text.split(\" \")\n",
    "                    if len(parts) >= 3:\n",
    "                        _, subject, year = parts[-3:]\n",
    "                    else:\n",
    "                        subject, year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "                    if clean_title and authors:\n",
    "                        data.append([clean_title, authors, year, subject + ' Nobel prize', link])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing article: {e}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")  # Log errors during scraping\n",
    "        data = []\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    print(f\"Finished scraping: {url}\")  # Notify when scraping for this URL is complete\n",
    "    # Save data to CSV\n",
    "    save_to_csv(data, output_csv)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Saves the collected data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Title', 'Author', 'Year', 'Type of Prize', 'url'])  # Write the header row with both Title and Author\n",
    "            writer.writerows(data)  # Write the collected data\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "extracted_data = extract_data(\"https://www.nobelprize.org/prizes/lists/all-nobel-prizes/\")\n",
    "print(f\"Total data collected: {len(extracted_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import required libraries\n",
    "# from kafka import KafkaProducer\n",
    "# import time\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to kafka broker running in your local host (docker). Change this to your kafka broker if needed\n",
    "# kafka_broker = 'localhost:29092'\n",
    "# producer = KafkaProducer(\n",
    "#     bootstrap_servers=[kafka_broker],\n",
    "#     linger_ms=5000,  # Increased linger time\n",
    "#     max_block_ms=60000,  # Increase the max block time (default: 60000 ms = 1 minute)\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
