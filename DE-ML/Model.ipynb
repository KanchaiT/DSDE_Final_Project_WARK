{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- citation_title: string (nullable = true)\n",
      " |-- abstracts: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- authors_with_location_department: string (nullable = true)\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- classifications: string (nullable = true)\n",
      " |-- subject_area_name: string (nullable = true)\n",
      " |-- subject_area_code: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- citedby_count: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------------------+--------------------+---------------+--------------------+-----------------+----------+-------------+--------------------+\n",
      "|      citation_title|           abstracts|             authors|authors_with_location_department|        affiliations|classifications|   subject_area_name|subject_area_code|      date|citedby_count|            category|\n",
      "+--------------------+--------------------+--------------------+--------------------------------+--------------------+---------------+--------------------+-----------------+----------+-------------+--------------------+\n",
      "|Mödruvallabók, AM...|The ultimate goal...|Arkel-de Leeuw va...|                               -|                   -|              -|                   -|                -|2017-12-31|            0|               Other|\n",
      "|  Energy and society|                   -|                   -|                               -|                   -|              -|                   -|                -|2017-12-31|            1|               Other|\n",
      "|PAHs in polystyre...|Eight low-ring PA...|Li Si-Qi; Ni Hong...|                               -|Shenzhen Key Labo...|              -|Food contact mate...|                -|2017-12-31|           41|Medicine and Heal...|\n",
      "|Techniques in int...|This article trac...| Sivakumaran Sandesh|                               -|Public Internatio...|              -|                   -|                -|2017-12-31|           20|               Other|\n",
      "|The responsibilit...|While histories o...|      Glanville Luke|                               -|Department of Int...|              -|                   -|                -|2017-12-31|            7|               Other|\n",
      "+--------------------+--------------------+--------------------+--------------------------------+--------------------+---------------+--------------------+-----------------+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/home/WARK/jdk-11.0.25+9\"  \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session with increased memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WARK Data Pipeline - Predict Subject Area\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Load CSV data into a Spark DataFrame\n",
    "data_path = \"/home/WARK/DSDE_Final_Project_WARK/Final/joined_2017-2023.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the data schema\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- citation_title: string (nullable = true)\n",
      " |-- abstracts: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- subject_area_name: string (nullable = true)\n",
      " |-- subject_area_code: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|      citation_title|           abstracts|             authors|        affiliations|   subject_area_name|subject_area_code|            category|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|Mödruvallabók, AM...|The ultimate goal...|Arkel-de Leeuw va...|                   -|                   -|                -|               Other|\n",
      "|  Energy and society|                   -|                   -|                   -|                   -|                -|               Other|\n",
      "|PAHs in polystyre...|Eight low-ring PA...|Li Si-Qi; Ni Hong...|Shenzhen Key Labo...|Food contact mate...|                -|Medicine and Heal...|\n",
      "|Techniques in int...|This article trac...| Sivakumaran Sandesh|Public Internatio...|                   -|                -|               Other|\n",
      "|The responsibilit...|While histories o...|      Glanville Luke|Department of Int...|                   -|                -|               Other|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the redundant column\n",
    "# df = df.drop('authors')\n",
    "df = df.drop('authors_with_location_department')\n",
    "# df = df.drop('affiliations')\n",
    "df = df.drop('classifications')\n",
    "# df = df.drop('subject_area_name')\n",
    "# df = df.drop('subject_area_code')\n",
    "df = df.drop('date')\n",
    "df = df.drop('citedby_count')\n",
    "\n",
    "# Show the data schema\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /home/WARK/.venv/lib/python3.11/site-packages (75.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------+\n",
      "|features_combined                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |category                           |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------+\n",
      "|Mödruvallabók, AM 132 Fol.: Volume One: Index and Concordance||The ultimate goal of the Modruvallabok Project is a description of the language in Modruvallabok. Publication of a survey of the orthography and morphology is planned for the not too distant future. It was deemed, however, to be in the interest of Old Icelandic research that the concordance and index should be made available to the public as soon as possible. As an index or concordance to an -practically -unavailable text is an absurdity, it was decided to include the transcription of the text as well. Of course, the publication will come into its own only when more texts have been treated in the same way and comparison, both synchronic and diachronic, has become possible. It is hoped, however, that the study of Old Icelandic will already now profit from this work. Users are kindly requested to forward details to the publisher of any errors they may discover in the text and index. © 1987 by E. J. Brill, Leiden, The Netherlands. All rights reserved.||Arkel-de Leeuw van Weenen Andrea van||-||-||-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |Other                              |\n",
      "|Energy and society||-||-||-||-||-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |Other                              |\n",
      "|PAHs in polystyrene food contact materials: An unintended consequence||Eight low-ring PAHs were detected in 21 polystyrene (PS) food contact materials (FCMs) samples while high-ring PAHs (> 4 rings) were not found. This is because the reaction pathway for formation of high-ring PAHs consists of more steps than it does for low-high PAHs. The concentrations of Σ8PAH were from 18.9 ± 5.16 ng/g for product colorless fruit fork to 476 ± 52.0 ng/g for foam instant noodle container. These data were far beyond levels of PAHs in other plastics. Of the eight PAHs detected, Phe had the highest average concentration, followed by Nap. These two PAHs collectively accounted for over 80% of the Σ8PAH concentrations in all PS FCMs. Levels of Σ8PAH in expanded PS FCMs were higher than those in extruded ones due to utilization of foaming agent. The concentrations of Σ8PAH were lower in colorless PS FCMs than in colored ones. Auxochromes and chromophores contributed to the change of short-chain hydrocarbons to aromatic hydrocarbon. Simulated migration values of PAHs from PS FCMs to food varied widely. The migration value of Σ8PAH with maximum probability was below 10 ng/g, which the maximum tolerated migration level for substance according to the European Union standards. However, higher migration values were possible and the potential health risk should still be concerned because the simulated migration displayed a log-normal distribution. Furthermore, water was used as food simulant would always lead to an underestimate of PAHs migration to real daily food, and then lead to an underestimate of risk. © 2017 Elsevier B.V.||Li Si-Qi; Ni Hong-Gang; Zeng Hui||Shenzhen Key Laboratory of Circular Economy\\Shenzhen Graduate School\\China||Food contact material; Migration; PAH; Polystyrene; Potential health risk||-|Medicine and Health Sciences; Other|\n",
      "|Techniques in international law-making: Extrapolation, analogy, form and the emergence of an international law of disaster relief||This article traces the emergence of an international law of disaster relief from a patchwork of norms through to a holistic body of international law. It argues that, for many years, the international law of disaster relief existed in piecemeal fashion. Since there is no overarching treaty on the subject at the global level, a hodgepodge of instruments have been concluded, namely subject-specific and disaster-specific treaties at the global level, regional and sub-regional agreements, bilateral agreements as well as soft law. However, through the work of the International Law Commission and the International Federation of the Red Cross and Red Crescent, a holistic body of international law relating to disaster relief is in the process of emerging. This article argues that this holistic body is emerging primarily as a result of three techniques that, while unconventional, are used relatively frequently in the making of international law. The three techniques are: (i) extrapolation from a series of piecemeal instruments to form a generalized standard; (ii) the use of analogy and (iii) the conclusion of instruments that are soft in form but contain a mixture of hard law and soft law. The way in which the techniques have been used to develop a body of international law relating to disaster relief is analysed, their use in other fields of international law discussed and limitations on their use in the disaster law context identified. © The Author(s), 2018. Published by Oxford University Press on behalf of EJIL Ltd. All rights reserved.||Sivakumaran Sandesh||Public International Law\\University of Nottingham\\United Kingdom||-||-                                    |Other                              |\n",
      "|The responsibility to protect beyond borders in the Law of Nature and Nations||While histories of human rights have proliferated in recent decades, little attention has been given to the history of thinking about duties to protect these rights beyond sovereign borders. We have a good understanding of the history of duties of sovereign states to ensure the safety and well-being of their own citizens and of the right of other states to forcefully intervene when these duties are violated. But the story of the development of thinking about duties to assist and protect the vulnerable beyond borders remains to be told. This article defends the importance of excavating and examining past thinking about these duties. It then sketches key aspects of Western natural law thinking about such duties, from Francisco de Vitoria through to Immanuel Kant, claiming that such study holds the promise of exposing from where ideas that prevail in international law and politics have come and retrieving alternative ideas that have been long forgotten but that may reward renewed consideration. It concludes by briefly outlining how three such retrieved ideas might be of particular use for those seeking to push international law and politics in a more just direction today. © The Author(s), 2018. Published by Oxford University Press on behalf of EJIL Ltd. All rights reserved.||Glanville Luke||Department of International Relations\\Australian National University\\Australia||-||-                                                                                                                                                                                                                                                                                                                                                         |Other                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "%pip install setuptools\n",
    "\n",
    "# Replace null or missing values\n",
    "df_cleaned = df.fillna({\n",
    "    'citation_title': '-',\n",
    "    'abstracts': '-',\n",
    "    'authors': '-',\n",
    "    'affiliations': '-',\n",
    "    'subject_area_name' : '-',\n",
    "    'subject_area_code' : '-',\n",
    "    'category': '-',\n",
    "})\n",
    "\n",
    "# Combine relevant fields into a single feature\n",
    "df_cleaned = df_cleaned.withColumn(\n",
    "    \"features_combined\", \n",
    "    concat_ws(\"||\", col(\"citation_title\"), col(\"abstracts\"), col(\"authors\"), col('affiliations'), col(\"subject_area_name\"), col(\"subject_area_code\"))\n",
    ")\n",
    "\n",
    "# Show the combined features\n",
    "df_cleaned.select(\"features_combined\", \"category\").show(5, truncate=False)\n",
    "\n",
    "\n",
    "# Ensure no null values in required columns\n",
    "df_cleaned = df_cleaned.fillna({\"features_combined\": \"-\", \"category\": \"-\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(30000,[0,1,2,5,7...|  1.0|\n",
      "|(30000,[2,121],[1...|  1.0|\n",
      "|(30000,[0,1,2,5,7...|  5.0|\n",
      "|(30000,[0,1,2,5,7...|  1.0|\n",
      "|(30000,[0,1,2,5,7...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize the combined features\n",
    "tokenizer = Tokenizer(inputCol=\"features_combined\", outputCol=\"tokens\")\n",
    "\n",
    "# Convert tokens into numerical features\n",
    "vectorizer = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=30000)\n",
    "\n",
    "# Encode target labels into numerical format\n",
    "label_indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(stages=[tokenizer, vectorizer, label_indexer])\n",
    "\n",
    "# Fit and transform the data\n",
    "preprocessed_data = preprocessing_pipeline.fit(df_cleaned).transform(df_cleaned)\n",
    "\n",
    "# Verify the transformed data\n",
    "preprocessed_data.select(\"features\", \"label\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(30000,[0,1,2,5,7...|  1.0|\n",
      "|(30000,[2,121],[1...|  1.0|\n",
      "|(30000,[0,1,2,5,7...|  5.0|\n",
      "|(30000,[0,1,2,5,7...|  1.0|\n",
      "|(30000,[0,1,2,5,7...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 487:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Count: 15042, Test Data Count: 6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check if features and label columns are present\n",
    "preprocessed_data.select(\"features\", \"label\").show(5)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = preprocessed_data.randomSplit([0.7, 0.3], seed=39)\n",
    "\n",
    "# # Sample a fraction of the data\n",
    "# train_data = train_data.sample(fraction=1, seed=42)\n",
    "# test_data = test_data.sample(fraction=1, seed=42)\n",
    "\n",
    "\n",
    "print(f\"Training Data Count: {train_data.count()}, Test Data Count: {test_data.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 08:54:01 WARN DAGScheduler: Broadcasting large task binary with size 162.0 MiB\n",
      "[Stage 578:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(30000,[0,1,2,5,7...| 45.0|       1.0|\n",
      "|(30000,[19236],[1...|  1.0|       1.0|\n",
      "|(30000,[19236],[1...|  1.0|       1.0|\n",
      "|(30000,[19236],[1...|  1.0|       1.0|\n",
      "|(30000,[19236],[1...|  1.0|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=40)\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Display predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 08:54:03 WARN DAGScheduler: Broadcasting large task binary with size 162.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
