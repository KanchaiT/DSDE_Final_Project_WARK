{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.5.3.tar.gz (317.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (pyproject.toml): started\n",
      "  Building wheel for pyspark (pyproject.toml): still running...\n",
      "  Building wheel for pyspark (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840672 sha256=80aa6ab6d79b5bb028f0abe6b5542391e02981ceb781810d57a24ba706616163\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\57\\01\\5d\\dd344b64ae939cd8ea67ffa0abd6aed72f14b1165228e281a0\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- citation_title: string (nullable = true)\n",
      " |-- abstracts: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- classifications: string (nullable = true)\n",
      " |-- subject_area_name: string (nullable = true)\n",
      " |-- subject_area_code: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      citation_title|           abstracts|             authors|        affiliations|     classifications|   subject_area_name|   subject_area_code|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Public health and...|                   -|Pongpirul Krit; L...|Stanford Universi...|ASJC: 2700; SUBJA...|      Medicine (all)|                2700|\n",
      "|Flexible Printed ...|© 2018 The Instit...|Pratumsiri Teerap...|Chulalongkorn Uni...|ASJC: 2208\\2504; ...|Electrical and El...|          2208; 2504|\n",
      "|Parametric study ...|© 2018 Elsevier L...|Phuakpunk Kiattik...|Chulalongkorn Uni...|CPXCLASS: 522\\723...|Chemistry (all); ...|    1600; 1500; 2209|\n",
      "|Superhydrophobic ...|© 2018 Elsevier B...|Saengkaew Jittrap...|Hirosaki Universi...|CPXCLASS: 641.1\\7...|Chemistry (all); ...|1600; 3104; 3100;...|\n",
      "|Electrochemical i...|© 2018 Elsevier B...|Teengam Prinjapor...|Chulalongkorn Uni...|EMCLASS: 4; ASJC:...|Analytical Chemis...|1602; 1303; 2304;...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session with increased memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WARK Data Pipeline - Predict Subject Area\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Load CSV data into a Spark DataFrame\n",
    "data_path = \"C:/Users/Public/Documents/My/DataSci/DSDE_Final_Project_WARK/Data_Aj/2/joined_2018-2023.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the data schema\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- citation_title: string (nullable = true)\n",
      " |-- abstracts: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- classifications: string (nullable = true)\n",
      " |-- subject_area_name: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      citation_title|           abstracts|             authors|        affiliations|     classifications|   subject_area_name|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Public health and...|                   -|Pongpirul Krit; L...|Stanford Universi...|ASJC: 2700; SUBJA...|      Medicine (all)|\n",
      "|Flexible Printed ...|© 2018 The Instit...|Pratumsiri Teerap...|Chulalongkorn Uni...|ASJC: 2208\\2504; ...|Electrical and El...|\n",
      "|Parametric study ...|© 2018 Elsevier L...|Phuakpunk Kiattik...|Chulalongkorn Uni...|CPXCLASS: 522\\723...|Chemistry (all); ...|\n",
      "|Superhydrophobic ...|© 2018 Elsevier B...|Saengkaew Jittrap...|Hirosaki Universi...|CPXCLASS: 641.1\\7...|Chemistry (all); ...|\n",
      "|Electrochemical i...|© 2018 Elsevier B...|Teengam Prinjapor...|Chulalongkorn Uni...|EMCLASS: 4; ASJC:...|Analytical Chemis...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the redundant column\n",
    "df = df.drop('subject_area_code')\n",
    "\n",
    "# Show the data schema\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|features_combined                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |subject_area_name                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|Public health and international epidemiology for radiology||-||Pongpirul Krit; Lungren Matthew P.||Stanford University School of Medicine\\Stanford\\United States; Chulalongkorn University\\Bangkok\\Thailand; Bumrungrad International Hospital\\Bangkok\\Thailand; Stanford Healthcare\\Stanford\\United States; Stanford University\\Palo Alto\\United States; Johns Hopkins Bloomberg School of Public Health\\Baltimore\\United States||ASJC: 2700; SUBJABBR: MEDI                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |Medicine (all)                                                                                                               |\n",
      "|Flexible Printed Active Antenna for Digital Television Reception||© 2018 The Institute of Electronics, Information and Communication Engineers (IEICE).This paper presents the development of a flexible printed active antenna for the digital television (DTV) reception in areas having poor signal or in high-rise buildings. The antenna structure is composed of a meander line printed on a polyimide film as a radiating element. It has a thickness of 0.3 mm, highly flexible, and very lightweight. The design and analysis of the radiating element are based on a full-wave method implemented by a commercial electromagnetic simulation software. The amplifier circuit consisting of a surface-mount transistor and passive components are integrated directly on the polyimide film, residing next to the feedline, to improve the antenna performance and minimize the whole antenna dimension. The impedance matching between the radiating element, the feed line, and the active circuit are considered. The measured results show that the return loss of more than approximately 10 dB, the maximum gain of about 18 dB, and the Omni-directional radiation pattern are achieved in the operating frequency band of 510-790 MHz. Due to its flexibility, low profile, lightweight, and additional gain, the proposed antenna could be useful for various specific applications.||Pratumsiri Teerapong; Janpugdee Panuwat||Chulalongkorn University\\Bangkok\\Thailand||ASJC: 2208\\2504; CPXCLASS: 402\\714.2\\716\\716.4\\723\\815.1.1; FLXCLASS: 902; SUBJABBR: ENGI\\MATE                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |Electrical and Electronic Engineering; Electronic, Optical and Magnetic Materials                                            |\n",
      "|Parametric study of hydrogen production via sorption enhanced steam methane reforming in a circulating fluidized bed riser||© 2018 Elsevier LtdComputational fluid dynamics was applied for sorption enhanced steam methane reforming (SESMR) operating in a circulating fluidized bed (CFB) riser. The solid mixtures consisted of Ni-based catalyst and CaO sorbent. The aim of study was to design a proper pilot-scale CFB riser which produced hydrogen (H2) with both high purity and high flux. The design parameters and the reaction parameters were examined with 2k full factorial design. The significances of each parameter were analyzed by analysis of variance. Using the optimum result, the highest H2 purity reached 98.58% in dry basis accompanied with the highest H2 flux of 0.301 kg/m2 s. The hydrodynamics of this optimum case showed that SESMR was nearly completed since 5.0 m height because axial and radial distributions of solid were well developed without excessive segregation between catalyst and sorbent. Thus, the H2 purity and the H2 flux approached fully developed within the riser height.||Phuakpunk Kiattikhoon; Chalermsinsuwan Benjapon; Putivisutisak Sompong; Assabumrungrat Suttichai||Chulalongkorn University\\Bangkok\\Thailand||CPXCLASS: 522\\723.5\\802.2\\802.3\\803\\804\\804.1; ENCOMPASSCLASS: 306.5.1\\306.6.1\\307.3.1; FLXCLASS: 78.22; ASJC: 1600\\1500\\2209; SUBJABBR: CHEM\\CENG\\ENGI                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |Chemistry (all); Chemical Engineering (all); Industrial and Manufacturing Engineering                                        |\n",
      "|Superhydrophobic coating from fluoroalkylsilane modified natural rubber encapsulated SiO 2 composites for self-driven oil/water separation||© 2018 Elsevier B.V. A superhydrophobic/superoleophilic mesh was successfully prepared in a simple and environmentally friendly process by coating with fluoroalkylsilane-modified natural rubber-encapsulated silica latex (FAS-modified NR/SiO 2 ). TEM images confirmed the formation of a core-shell morphology, in which the rubber core was fully covered by a silica shell. This improved the thermal stability of the composites. Coating with FAS-modified NR/SiO 2 enhanced both the hydrophobicity and surface roughness of the mesh. The depth profile of the XPS spectra revealed the presence of fluoroalkylsilane on the superhydrophobic mesh and Ar gas ion etching confirmed migration of the fluoroalkylsilane, SiO 2 and carbon to the mesh surface. SEM and AFM results quantified the surface roughness of the coated mesh. Meshes coated with FAS-modified NR/SiO 2 exhibited superhydrophobic/superoleophilic properties. Surfaces coated with these encapsulated particles were successfully applied to oil/water separation. They exhibited a separation efficiency of up to 100% and were reusable across 30 cycles.||Saengkaew Jittraporn; Le Duy; Samart Chanatip; Sawada Hideo; Nishida Masakazu; Chanlek Narong; Kongparakul Suwadee; Kiatkamjornwong Suda||Hirosaki University\\Hirosaki\\Japan; Chulalongkorn University\\Bangkok\\Thailand; Thammasat University\\Pathum Thani\\Thailand; National Institute of Advanced Industrial Science and Technology, Chubu\\Nagoya\\Japan; Synchrotron Light Research Institute (Public Organization)\\Nakhon Ratchasima\\Thailand; Academy of Science\\North Bangkok\\Thailand||CPXCLASS: 641.1\\723.5\\802.3\\813.2\\818.1\\931.2; FLXCLASS: 902; ASJC: 1600\\3104\\3100\\3110\\2508; SUBJABBR: CHEM\\PHYS\\MATE                                                                                                                                                                                                                                                                                                                                                                               |Chemistry (all); Condensed Matter Physics; Physics and Astronomy (all); Surfaces and Interfaces; Surfaces, Coatings and Films|\n",
      "|Electrochemical impedance-based DNA sensor using pyrrolidinyl peptide nucleic acids for tuberculosis detection||© 2018 Elsevier B.V. A label-free electrochemical DNA sensor based on pyrrolidinyl peptide nucleic acid (acpcPNA)-immobilized on a paper-based analytical device (PAD) was developed. Unlike previous PNA-based electrochemical PAD (ePAD) sensors where the capture element was placed directly on the electrode, acpcPNA was covalently immobilized onto partially oxidized cellulose paper allowing regeneration by simple PAD replacement. As an example application, a sensor probe was designed for Mycobacterium tuberculosis (MTB) detection. The ePAD DNA sensor was used to determine a synthetic 15-base oligonucleotide of MTB by measuring the fractional change in the charge transfer resistance (R ct ) obtained from electrochemical impedance spectroscopy (EIS). The R ct of [Fe(CN) 6 ] 3-/4- before and after hybridization with the target DNA could be clearly distinguished. Cyclic voltammetry (CV) was used to verify the EIS results, and showed an increase in peak potential splitting in a similar stepwise manner for each immobilization step. Under optimal conditions, a linear calibration curve in the range of 2–200 nM and the limit of detection 1.24 nM were measured. The acpcPNA probe exhibited very high selectivity for complementary oligonucleotides over single-base-mismatch, two-base-mismatch and non-complementary DNA targets due to the conformationally constrained structure of the acpcPNA. Moreover, the ePAD DNA sensor platform was successfully applied to detect PCR-amplified MTB DNA extracted from clinical samples. The proposed paper-based electrochemical DNA sensor has potential to be an alternative device for low-cost, simple, label-free, sensitive and selective DNA sensor.||Teengam Prinjaporn; Siangproh Weena; Tuantranont Adisorn; Vilaivan Tirayut; Chailapakul Orawon; Henry Charles S.||Chulalongkorn University\\Bangkok\\Thailand; Thailand National Electronics and Computer Technology Center\\Pathum Thani\\Thailand; Colorado State University\\Fort Collins\\United States; Srinakharinwirot University\\Bangkok\\Thailand||EMCLASS: 4; ASJC: 1602\\1303\\2304\\1607; SUBJABBR: CHEM\\BIOC\\ENVI|Analytical Chemistry; Biochemistry; Environmental Chemistry; Spectroscopy                                                    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "\n",
    "# Replace null or missing values\n",
    "df_cleaned = df.fillna({\n",
    "    'citation_title': '-',\n",
    "    'abstracts': '-',\n",
    "    'authors': '-',\n",
    "    'affiliations': '-',\n",
    "    'classifications': '-',\n",
    "    'subject_area_name': '-',\n",
    "})\n",
    "\n",
    "# Combine relevant fields into a single feature\n",
    "df_cleaned = df_cleaned.withColumn(\n",
    "    \"features_combined\", \n",
    "    concat_ws(\"||\", col(\"citation_title\"), col(\"abstracts\"), col(\"authors\"), col(\"affiliations\"), col(\"classifications\"))\n",
    ")\n",
    "\n",
    "# Show the combined features\n",
    "df_cleaned.select(\"features_combined\", \"subject_area_name\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features| label|\n",
      "+--------------------+------+\n",
      "|(5000,[1,2,6,10,1...|   1.0|\n",
      "|(5000,[0,1,2,3,4,...|2615.0|\n",
      "|(5000,[0,1,2,3,4,...| 119.0|\n",
      "|(5000,[0,1,2,3,4,...| 191.0|\n",
      "|(5000,[0,1,2,3,4,...| 230.0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Ensure no null values in required columns\n",
    "df_cleaned = df_cleaned.fillna({\"features_combined\": \"-\", \"subject_area_name\": \"-\"})\n",
    "\n",
    "# Tokenize the combined features\n",
    "tokenizer = Tokenizer(inputCol=\"features_combined\", outputCol=\"tokens\")\n",
    "\n",
    "# Convert tokens into numerical features\n",
    "vectorizer = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=5000)\n",
    "\n",
    "# Encode target labels into numerical format\n",
    "label_indexer = StringIndexer(inputCol=\"subject_area_name\", outputCol=\"label\")\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(stages=[tokenizer, vectorizer, label_indexer])\n",
    "\n",
    "# Fit and transform the data\n",
    "preprocessed_data = preprocessing_pipeline.fit(df_cleaned).transform(df_cleaned)\n",
    "\n",
    "# Verify the transformed data\n",
    "preprocessed_data.select(\"features\", \"label\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features| label|\n",
      "+--------------------+------+\n",
      "|(5000,[1,2,6,10,1...|   1.0|\n",
      "|(5000,[0,1,2,3,4,...|2615.0|\n",
      "|(5000,[0,1,2,3,4,...| 119.0|\n",
      "|(5000,[0,1,2,3,4,...| 191.0|\n",
      "|(5000,[0,1,2,3,4,...| 230.0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Training Data Count: 1378, Test Data Count: 610\n"
     ]
    }
   ],
   "source": [
    "# Check if features and label columns are present\n",
    "preprocessed_data.select(\"features\", \"label\").show(5)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = preprocessed_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Sample a fraction of the data\n",
    "train_data = train_data.sample(fraction=0.1, seed=42)\n",
    "test_data = test_data.sample(fraction=0.1, seed=42)\n",
    "\n",
    "\n",
    "print(f\"Training Data Count: {train_data.count()}, Test Data Count: {test_data.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the logistic regression model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeaturesCol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelCol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxIter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mfit(train_data)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\pyspark\\__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m forces keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\pyspark\\ml\\classification.py:1318\u001b[0m, in \u001b[0;36mLogisticRegression.__init__\u001b[1;34m(self, featuresCol, labelCol, predictionCol, maxIter, regParam, elasticNetParam, tol, fitIntercept, threshold, thresholds, probabilityCol, rawPredictionCol, standardization, weightCol, aggregationDepth, family, lowerBoundsOnCoefficients, upperBoundsOnCoefficients, lowerBoundsOnIntercepts, upperBoundsOnIntercepts, maxBlockSizeInMB)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m__init__(self, \\\\*, featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", \\\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03m         maxIter=100, regParam=0.0, elasticNetParam=0.0, tol=1e-6, fitIntercept=True, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;124;03mIf the threshold and thresholds Params are both set, they must be equivalent.\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28msuper\u001b[39m(LogisticRegression, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m-> 1318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_java_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark.ml.classification.LogisticRegression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muid\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1321\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetParams(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:80\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[1;34m(java_class, *args)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03mReturns a new Java object.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     82\u001b[0m java_obj \u001b[38;5;241m=\u001b[39m _jvm()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m java_class\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Display predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "lr_model.save(\"logistic_regression_model\")\n",
    "\n",
    "# Save the preprocessing pipeline\n",
    "preprocessing_pipeline.save(\"preprocessing_pipeline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "# Load the pipeline and model\n",
    "loaded_pipeline = PipelineModel.load(\"preprocessing_pipeline\")\n",
    "loaded_model = LogisticRegressionModel.load(\"logistic_regression_model\")\n",
    "\n",
    "# Process new data\n",
    "new_data = spark.createDataFrame([{\n",
    "    \"citation_title\": \"New Research in AI\",\n",
    "    \"abstracts\": \"Deep learning advances...\",\n",
    "    \"authors\": \"Author A; Author B\",\n",
    "    \"affiliations\": \"University of XYZ\",\n",
    "    \"classifications\": \"ASJC: 1700; SUBJABBR: COMP\",\n",
    "    \"subject_area_name\": \"Unknown\"\n",
    "}])\n",
    "\n",
    "new_data_cleaned = loaded_pipeline.transform(new_data)\n",
    "new_predictions = loaded_model.transform(new_data_cleaned)\n",
    "new_predictions.select(\"features\", \"prediction\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
